# 第 2 节 Pandas 数据处理（下）

## 数值运算

### 统计

运算通常会排除缺省项

求平均值：

```py
df.mean() 
```

输出：

```py
A   -0.004474
B   -0.383981
C   -0.687758
D    5.000000
F    3.000000
dtype: float64 
```

求指定轴上的平均值

```py
df.mean(1) 
```

输出：

```py
2013-01-01    0.872735
2013-01-02    1.431621
2013-01-03    0.707731
2013-01-04    1.395042
2013-01-05    1.883656
2013-01-06    1.592306
Freq: D, dtype: float64 
```

不同维度的 pandas 对象也可以做运算，它会自动进行对应，`shift` 用来做对齐操作。

```py
s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)
s 
```

输出：

```py
2013-01-01   NaN
2013-01-02   NaN
2013-01-03     1
2013-01-04     3
2013-01-05     5
2013-01-06   NaN
Freq: D, dtype: float64 
```

对不同维度的 pandas 对象进行减法操作：

```py
df.sub(s, axis='index') 
```

输出：

```py
 A         B         C   D   F
2013-01-01       NaN       NaN       NaN NaN NaN
2013-01-02       NaN       NaN       NaN NaN NaN
2013-01-03 -1.861849 -3.104569 -1.494929   4   1
2013-01-04 -2.278445 -3.706771 -4.039575   2   0
2013-01-05 -5.424972 -4.432980 -4.723768   0  -1
2013-01-06       NaN       NaN       NaN NaN NaN 
```

### 函数应用

对数据应用 numpy 函数：

```py
df.apply(np.cumsum) #累加 
```

输出：

```py
 A         B         C   D   F
2013-01-01  0.000000  0.000000 -1.509059   5 NaN
2013-01-02  1.212112 -0.173215 -1.389850  10   1
2013-01-03  0.350263 -2.277784 -1.884779  15   3
2013-01-04  1.071818 -2.984555 -2.924354  20   6
2013-01-05  0.646846 -2.417535 -2.648122  25  10
2013-01-06 -0.026844 -2.303886 -4.126549  30  15 
```

应用自定义函数：

```py
df.apply(lambda x: x.max() - x.min()) 
```

输出：

```py
A    2.073961
B    2.671590
C    1.785291
D    0.000000
F    4.000000
dtype: float64 
```

### 直方图

对不同值的数量进行统计

```py
s = pd.Series(np.random.randint(0, 7, size=10))
s 
```

输出：

```py
0    4
1    2
2    1
3    2
4    6
5    4
6    4
7    6
8    4
9    4
dtype: int32 
```

输入：

```py
s.value_counts() 
```

输出：

```py
4    5
6    2
2    2
1    1
dtype: int64
String Methods 
```

### 字符处理

```py
s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])
s.str.lower() 
```

输出：

```py
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object 
```

## 合并

### Concat

使用 `concat()` 连接 pandas 对象:

```py
df = pd.DataFrame(np.random.randn(10, 4))
df 
```

输出：

```py
 0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495 
```

切片

```py
pieces = [df[:3], df[3:7], df[7:]]
pd.concat(pieces) 
```

输出：

```py
 0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495 
```

### Join

SQL 风格的合并

```py
left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})
right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]}) 
```

输入：

```py
left 
```

输出：

```py
 key  lval
0  foo     1
1  foo     2 
```

输入：

```py
right 
```

输出：

```py
 key  rval
0  foo     4
1  foo     5 
```

输入：

pd.merge(left, right, on='key')

输出：

```py
 key  lval  rval
0  foo     1     4
1  foo     1     5
2  foo     2     4
3  foo     2     5 
```

### 追加

在 dataframe 数据后追加行

```py
df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])
df 
```

输出：

```py
 A         B         C         D
0  1.346061  1.511763  1.627081 -0.990582
1 -0.441652  1.211526  0.268520  0.024580
2 -1.577585  0.396823 -0.105381 -0.532532
3  1.453749  1.208843 -0.080952 -0.264610
4 -0.727965 -0.589346  0.339969 -0.693205
5 -0.339355  0.593616  0.884345  1.591431
6  0.141809  0.220390  0.435589  0.192451
7 -0.096701  0.803351  1.715071 -0.708758 
```

输入：

```py
s = df.iloc[3]
df.append(s, ignore_index=True) 
```

输出：

```py
 A         B         C         D
0  1.346061  1.511763  1.627081 -0.990582
1 -0.441652  1.211526  0.268520  0.024580
2 -1.577585  0.396823 -0.105381 -0.532532
3  1.453749  1.208843 -0.080952 -0.264610
4 -0.727965 -0.589346  0.339969 -0.693205
5 -0.339355  0.593616  0.884345  1.591431
6  0.141809  0.220390  0.435589  0.192451
7 -0.096701  0.803351  1.715071 -0.708758
8  1.453749  1.208843 -0.080952 -0.264610 
```

## 分组

分组常常意味着可能包含以下的几种的操作中一个或多个

*   依据一些标准分离数据
*   对组单独地应用函数
*   将结果合并到一个数据结构中

输入：

```py
df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
                          'foo', 'bar', 'foo', 'foo'],
                   'B' : ['one', 'one', 'two', 'three',
                          'two', 'two', 'one', 'three'],
                   'C' : np.random.randn(8),
                   'D' : np.random.randn(8)})
df 
```

输出：

```py
 A      B         C         D
0  foo    one -1.202872 -0.055224
1  bar    one -1.814470  2.395985
2  foo    two  1.018601  1.552825
3  bar  three -0.595447  0.166599
4  foo    two  1.395433  0.047609
5  bar    two -0.392670 -0.136473
6  foo    one  0.007207 -0.561757
7  foo  three  1.928123 -1.623033 
```

对单个分组应用函数，数据被分成了 bar 组与 foo 组，分别计算总和。

```py
df.groupby('A').sum() 
```

输出：

```py
 C        D
A                     
bar -2.802588  2.42611
foo  3.146492 -0.63958 
```

依据多个列分组会构成一个分级索引：

```py
df.groupby(['A','B']).sum() 
```

输出：

```py
 C         D
A   B                        
bar one   -1.814470  2.395985
    three -0.595447  0.166599
    two   -0.392670 -0.136473
foo one   -1.195665 -0.616981
    three  1.928123 -1.623033
    two    2.414034  1.600434 
```

### 数据透视表

```py
df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,
                   'B' : ['A', 'B', 'C'] * 4,
                   'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,
                   'D' : np.random.randn(12),
                   'E' : np.random.randn(12)})
df 
```

输出：

```py
 A  B    C         D         E
0     one  A  foo  1.418757 -0.179666
1     one  B  foo -1.879024  1.291836
2     two  C  foo  0.536826 -0.009614
3   three  A  bar  1.006160  0.392149
4     one  B  bar -0.029716  0.264599
5     one  C  bar -1.146178 -0.057409
6     two  A  foo  0.100900 -1.425638
7   three  B  foo -1.035018  1.024098
8     one  C  foo  0.314665 -0.106062
9     one  A  bar -0.773723  1.824375
10    two  B  bar -1.170653  0.595974
11  three  C  bar  0.648740  1.167115 
```

生成数据透视表：

```py
pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C']) 
```

输出：

```py
C             bar       foo
A     B                    
one   A -0.773723  1.418757
      B -0.029716 -1.879024
      C -1.146178  0.314665
three A  1.006160       NaN
      B       NaN -1.035018
      C  0.648740       NaN
two   A       NaN  0.100900
      B -1.170653       NaN
      C       NaN  0.536826 
```

## 时间序列

pandas 拥有既简单又强大的频率变换重新采样功能，下面的例子从 1 次/秒 转换到了 1 次/5 分钟：

```py
rng = pd.date_range('1/1/2012', periods=100, freq='S')
ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)
ts.resample('5Min', how='sum') 
```

输出：

```py
2012-01-01    25083
Freq: 5T, dtype: int32 
```

本地化时区表示

```py
rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')
ts = pd.Series(np.random.randn(len(rng)), rng)
ts 
```

输出：

```py
2012-03-06    0.464000
2012-03-07    0.227371
2012-03-08   -0.496922
2012-03-09    0.306389
2012-03-10   -2.290613
Freq: D, dtype: float64 
```

输入：

```py
ts_utc = ts.tz_localize('UTC')
ts_utc 
```

输出：

```py
2012-03-06 00:00:00+00:00    0.464000
2012-03-07 00:00:00+00:00    0.227371
2012-03-08 00:00:00+00:00   -0.496922
2012-03-09 00:00:00+00:00    0.306389
2012-03-10 00:00:00+00:00   -2.290613
Freq: D, dtype: float64 
```

转化成其他时区

```py
ts_utc.tz_convert('US/Eastern') 
```

输出：

```py
2012-03-05 19:00:00-05:00    0.464000
2012-03-06 19:00:00-05:00    0.227371
2012-03-07 19:00:00-05:00   -0.496922
2012-03-08 19:00:00-05:00    0.306389
2012-03-09 19:00:00-05:00   -2.290613
Freq: D, dtype: float64 
```

时间跨度的转换

```py
rng = pd.date_range('1/1/2012', periods=5, freq='M')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts 
```

输出：

```py
2012-01-31   -1.134623
2012-02-29   -1.561819
2012-03-31   -0.260838
2012-04-30    0.281957
2012-05-31    1.523962
Freq: M, dtype: float64 
```

转换为周期

```py
ps = ts.to_period()
ps 
```

输出：

```py
2012-01   -1.134623
2012-02   -1.561819
2012-03   -0.260838
2012-04    0.281957
2012-05    1.523962
Freq: M, dtype: float64 
```

转换为时间戳

```py
ps.to_timestamp() 
```

输出：

```py
2012-01-01   -1.134623
2012-02-01   -1.561819
2012-03-01   -0.260838
2012-04-01    0.281957
2012-05-01    1.523962
Freq: MS, dtype: float64 
```

在周期与时间戳之间进行转换这一功能对一些算术函数很有用，在下面的例子中我们改变时间序列的相位。

```py
prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')
ts = pd.Series(np.random.randn(len(prng)), prng)
ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9
ts.head() 
```

输出：

```py
1990-03-01 09:00   -0.902937
1990-06-01 09:00    0.068159
1990-09-01 09:00   -0.057873
1990-12-01 09:00   -0.368204
1991-03-01 09:00   -1.144073
Freq: H, dtype: float64 
```

## 分类

```py
df = pd.DataFrame({"id":[1,2,3,4,5,6], "raw_grade":['a', 'b', 'b', 'a', 'a', 'e']}) 
```

将 `raw_grades` 转换成 `Categoricals` 类型。

```py
df["grade"] = df["raw_grade"].astype("category")
df["grade"] 
```

输出：

```py
0    a
1    b
2    b
3    a
4    a
5    e
Name: grade, dtype: category
Categories (3, object): [a, b, e] 
```

重命名分类

```py
df["grade"].cat.categories = ["very good", "good", "very bad"] 
```

对分类进行重排序，同时加入新的分类。

```py
df["grade"] = df["grade"].cat.set_categories(["very bad", "bad", "medium", "good", "very good"])
df["grade"] 
```

输出：

```py
0    very good
1         good
2         good
3    very good
4    very good
5     very bad
Name: grade, dtype: category
Categories (5, object): [very bad, bad, medium, good, very good] 
```

根据分类的顺序对数据进行排序

```py
df.sort("grade") 
```

输出：

```py
 id raw_grade      grade
5   6         e   very bad
1   2         b       good
2   3         b       good
0   1         a  very good
3   4         a  very good
4   5         a  very good 
```

按类别分组

```py
df.groupby("grade").size() 
```

输出：

```py
grade
very bad      1
bad         NaN
medium      NaN
good          2
very good     3
dtype: float64 
```

## 作图

```py
ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))
ts = ts.cumsum()
ts.plot() 
```

![此处输入图片的描述](img/document-uid8834labid1234timestamp1468334289904.jpg)

在 DataFrame 中, `plot()` 可以很方便地为所有列作图:

```py
df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,
                  columns=['A', 'B', 'C', 'D'])
df = df.cumsum()
plt.figure(); df.plot(); plt.legend(loc='best') 
```

![此处输入图片的描述](img/document-uid8834labid1234timestamp1468334313554.jpg)

## 数据 I/O

### CSV

保存到 csv 文件

```py
df.to_csv('foo.csv') 
```

从 csv 文件读取数据

```py
pd.read_csv('foo.csv') 
```

输出：

```py
 Unnamed: 0          A          B         C          D
0    2000-01-01   0.266457  -0.399641 -0.219582   1.186860
1    2000-01-02  -1.170732  -0.345873  1.653061  -0.282953
2    2000-01-03  -1.734933   0.530468  2.060811  -0.515536
3    2000-01-04  -1.555121   1.452620  0.239859  -1.156896
4    2000-01-05   0.578117   0.511371  0.103552  -2.428202
5    2000-01-06   0.478344   0.449933 -0.741620  -1.962409
6    2000-01-07   1.235339  -0.091757 -1.543861  -1.084753
..          ...        ...        ...       ...        ...
993  2002-09-20 -10.628548  -9.153563 -7.883146  28.313940
994  2002-09-21 -10.390377  -8.727491 -6.399645  30.914107
995  2002-09-22  -8.985362  -8.485624 -4.669462  31.367740
996  2002-09-23  -9.558560  -8.781216 -4.499815  30.518439
997  2002-09-24  -9.902058  -9.340490 -4.386639  30.105593
998  2002-09-25 -10.216020  -9.480682 -3.933802  29.758560
999  2002-09-26 -11.856774 -10.671012 -3.216025  29.369368

[1000 rows x 5 columns] 
```

### Excel

保存到 excel 文件

```py
df.to_excel('foo.xlsx', sheet_name='Sheet1') 
```

读取 excel 文件

```py
pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])

                    A          B         C          D
2000-01-01   0.266457  -0.399641 -0.219582   1.186860
2000-01-02  -1.170732  -0.345873  1.653061  -0.282953
2000-01-03  -1.734933   0.530468  2.060811  -0.515536
2000-01-04  -1.555121   1.452620  0.239859  -1.156896
2000-01-05   0.578117   0.511371  0.103552  -2.428202
2000-01-06   0.478344   0.449933 -0.741620  -1.962409
2000-01-07   1.235339  -0.091757 -1.543861  -1.084753
...               ...        ...       ...        ...
2002-09-20 -10.628548  -9.153563 -7.883146  28.313940
2002-09-21 -10.390377  -8.727491 -6.399645  30.914107
2002-09-22  -8.985362  -8.485624 -4.669462  31.367740
2002-09-23  -9.558560  -8.781216 -4.499815  30.518439
2002-09-24  -9.902058  -9.340490 -4.386639  30.105593
2002-09-25 -10.216020  -9.480682 -3.933802  29.758560
2002-09-26 -11.856774 -10.671012 -3.216025  29.369368

[1000 rows x 4 columns] 
```

## License

本作品在 [知识共享许可协议 3.0](https://creativecommons.org/licenses/by/3.0/) 下许可授权。